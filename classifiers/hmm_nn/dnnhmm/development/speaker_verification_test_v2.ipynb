{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/david/Documents/mastersCode/ubm/classifiers/hmm_nn/dnnhmm/development', '/Users/david/.conda/envs/ubm/lib/python310.zip', '/Users/david/.conda/envs/ubm/lib/python3.10', '/Users/david/.conda/envs/ubm/lib/python3.10/lib-dynload', '', '/Users/david/.conda/envs/ubm/lib/python3.10/site-packages', '/Users/david/Documents/mastersCode/ubm']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/david/Documents/mastersCode/ubm\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/david/.cache/torch/hub/snakers4_silero-vad_master\n",
      "Using cache found in /Users/david/.cache/torch/hub/snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import audio_datastore.audio_datastore as myads\n",
    "reload(myads)\n",
    "from importlib import reload\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from data.pitch_tracking_database.load_data import *\n",
    "speech_pitch_tracking_db = pickle.load(open(normalised_30,'rb'))\n",
    "ads = speech_pitch_tracking_db['ads']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# split ads\n",
    "developmentLabels = [\"M03\",\"M04\",\"M05\",\"M06\",\"M07\",\"M08\",\"M09\",\"M10\",\"F05\",\"F06\",\"F07\",\"F08\",\"F09\",\"F10\",\n",
    "                     \"F03\",\"F04\"]\n",
    "evaluationLabels = [\"M01\",\"M02\",\"F01\",\"F02\"]\n",
    "adsTrain = myads.subset(ads, developmentLabels)\n",
    "adsEvaluate = myads.subset(ads, evaluationLabels)\n",
    "numFilesPerSpeakerForEnrollment = 4\n",
    "adsEnroll, adsDet = myads.split(adsEvaluate, numFilesPerSpeakerForEnrollment)\n",
    "adsTest = adsDet\n",
    "# adsDet, adsTest = myads.split(adsDet, 2)\n",
    "# adsTrain.info('Train')\n",
    "# adsEnroll.info('Enroll')\n",
    "# adsTest.info('Test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from classifiers.classifier_base import ClassifierBase\n",
    "from my_torch.tuts2.torch_transforms import ComposeTransform\n",
    "\n",
    "def test_classifiers(ads_train, ads_test, classifiers: [ClassifierBase], verbose=False):\n",
    "    index = 1\n",
    "    if verbose:\n",
    "        print('running all')\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        if verbose:\n",
    "            print('\\n')\n",
    "            print('test #', index)\n",
    "        print(classifier.info)\n",
    "\n",
    "        classifier.train(ads_train)\n",
    "        classifier.test_all(ads_test)\n",
    "        index = index + 1\n",
    "        if verbose:\n",
    "            print('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import classifiers.hmm_nn.dnnhmm.classifier_dnn_hmm as classifier_dnn_hmm\n",
    "reload(classifier_dnn_hmm)\n",
    "\n",
    "import my_torch.tuts2.torch_transforms as torch_t\n",
    "reload(torch_t)\n",
    "from feature_extraction.fe_spafe.fe_spafe import FeatureExtractorMfcc\n",
    "\n",
    "# define fe methods\n",
    "\n",
    "fe_mfcc = FeatureExtractorMfcc()\n",
    "fe_mfcc.set_normalisation(adsDet)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# define classifiers\n",
    "\n",
    "classifier_a = classifier_dnn_hmm.ClassifierHMMDNN(\n",
    "    train_process=torch_t.ComposeTransform([\n",
    "        torch_t.FeMethodCheck(),\n",
    "        fe_mfcc\n",
    "    ]),\n",
    "    test_process=torch_t.ComposeTransform([\n",
    "    torch_t.FeMethodCheck(),\n",
    "    fe_mfcc,\n",
    "    ]),\n",
    "    fe_method=torch_t.ComposeTransform([\n",
    "    fe_mfcc,\n",
    "    ]),\n",
    "    info='base mfcc no augmentation'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running all\n",
      "\n",
      "\n",
      "test # 1\n",
      "base mfcc no augmentation\n",
      "input vector shape incorrect\n",
      "input vector shape incorrect\n",
      "input vector shape incorrect\n",
      "input vector shape incorrect\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtest_classifiers\u001B[49m\u001B[43m(\u001B[49m\u001B[43madsEnroll\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madsTest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mclassifier_a\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 15\u001B[0m, in \u001B[0;36mtest_classifiers\u001B[0;34m(ads_train, ads_test, classifiers, verbose)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest #\u001B[39m\u001B[38;5;124m'\u001B[39m, index)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(classifier\u001B[38;5;241m.\u001B[39minfo)\n\u001B[0;32m---> 15\u001B[0m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mads_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m classifier\u001B[38;5;241m.\u001B[39mtest_all(ads_test)\n\u001B[1;32m     17\u001B[0m index \u001B[38;5;241m=\u001B[39m index \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Documents/mastersCode/ubm/classifiers/hmm_nn/dnnhmm/classifier_dnn_hmm.py:39\u001B[0m, in \u001B[0;36mClassifierHMMDNN.train\u001B[0;34m(self, ads_train)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# features_flattened = np.array([item for sublist in features for item in sublist])\u001B[39;00m\n\u001B[1;32m     38\u001B[0m model \u001B[38;5;241m=\u001B[39m DNNHMM(n_mix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_mix, n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components)\n\u001B[0;32m---> 39\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels[speakers[s]] \u001B[38;5;241m=\u001B[39m model\n",
      "File \u001B[0;32m~/Documents/mastersCode/ubm/classifiers/hmm_nn/dnnhmm/development/dnnhmm.py:45\u001B[0m, in \u001B[0;36mDNNHMM.fit\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, features):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_hmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m     sequences \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mviterbi_hmm(features)\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_mlp(features, sequences)\n",
      "File \u001B[0;32m~/Documents/mastersCode/ubm/classifiers/hmm_nn/dnnhmm/development/dnnhmm.py:53\u001B[0m, in \u001B[0;36mDNNHMM.train_hmm\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n, i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(features):\n\u001B[1;32m     52\u001B[0m     lengths\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mlen\u001B[39m(i))\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhmm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/ubm/lib/python3.10/site-packages/hmmlearn/base.py:496\u001B[0m, in \u001B[0;36mBaseHMM.fit\u001B[0;34m(self, X, lengths)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, lengths\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;124;03m    Estimate model parameters.\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;124;03m        Returns self.\u001B[39;00m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 496\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init(X)\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check()\n",
      "File \u001B[0;32m~/.conda/envs/ubm/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    893\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    894\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    895\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    896\u001B[0m         )\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 899\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    907\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/.conda/envs/ubm/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    125\u001B[0m             \u001B[38;5;129;01mnot\u001B[39;00m allow_nan\n\u001B[1;32m    126\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m estimator_name\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    131\u001B[0m             \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    132\u001B[0m             msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    133\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    134\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    144\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m             )\n\u001B[0;32m--> 146\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nan:\n",
      "\u001B[0;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "test_classifiers(adsEnroll, adsTest, [classifier_a], verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
