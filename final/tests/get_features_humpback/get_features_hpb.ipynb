{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/david/Documents/mastersCode/ubm/final/tests/get_features_humpback', '/Users/david/.conda/envs/ubm/lib/python310.zip', '/Users/david/.conda/envs/ubm/lib/python3.10', '/Users/david/.conda/envs/ubm/lib/python3.10/lib-dynload', '', '/Users/david/.conda/envs/ubm/lib/python3.10/site-packages', '/Users/david/Documents/mastersCode/ubm']\n"
     ]
    }
   ],
   "source": [
    "# create feature pickles to use around the place\n",
    "# humpback whale pickle with new annots\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/david/Documents/mastersCode/ubm\")\n",
    "print(sys.path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def get_feature(samp, nfft, fs=4000):\n",
    "    # add optionals here if needed\n",
    "    # mfcc\n",
    "    feat = librosa.feature.mfcc(y=samp,sr=fs, n_mfcc=4, n_fft=nfft,hop_length=int(nfft/4)).T\n",
    "    # feat = useful.get_log_power_feature(samp, nfft=nfft)[2:,:]\n",
    "    return feat\n",
    "\n",
    "def normalize_features(feats, per_feature=False):\n",
    "    if per_feature:\n",
    "        normalised_feats = []\n",
    "        for feat in feats:\n",
    "            mean = np.mean(feat, axis=0)\n",
    "            std_dev = np.std(feat, axis=0)\n",
    "            normalised_feats.append((feat - mean) / std_dev)\n",
    "        return normalised_feats\n",
    "    else:\n",
    "        all_features_concat = np.concatenate(feats)\n",
    "        mean = np.mean(all_features_concat, axis=0)\n",
    "        std_dev = np.std(all_features_concat, axis=0)\n",
    "        return [((feat - mean) / std_dev) for feat in feats], {'mean': mean, 'std': std_dev}\n",
    "\n",
    "def average_features(some_feature, avg_over, d):\n",
    "    new_n = len(some_feature) // avg_over\n",
    "    avg_features = np.empty((new_n, d))\n",
    "\n",
    "    for i in range(new_n):\n",
    "        start_idx = i * avg_over\n",
    "        end_idx = (i + 1) * avg_over\n",
    "        avg_features[i, :] = np.mean(some_feature[start_idx:end_idx, :], axis=0)\n",
    "    return avg_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from whale.setup import get_data, constants, annotations\n",
    "from whale.setup.constants_01 import *\n",
    "import importlib\n",
    "importlib.reload(constants)\n",
    "\n",
    "importlib.reload(get_data)\n",
    "from final import useful\n",
    "importlib.reload(useful)\n",
    "\n",
    "# constants for fe and what not\n",
    "fs = 4000 #4000 49000\n",
    "\n",
    "labels_set = ['MOO', 'HIGH_MOO', 'LOW_MOO', 'PULSE', 'SWOOP', 'NOISE']\n",
    "\n",
    "num_to_label = {i: labels_set[i] for i in range(len(labels_set))}\n",
    "label_to_num = {labels_set[i] : i for i in range(len(labels_set))}\n",
    "\n",
    "get_data_dict = {\n",
    "    'MOO': [get_data.GetDataSimple(HPB_MBY_DATA,HPB_MBY_LABEL_MOO, fs, useful.file_to_audio)],\n",
    "    'HIGH_MOO': [get_data.GetDataSimple(HPB_MBY_DATA,HPB_MBY_LABEL_HIGH_MOO, fs, useful.file_to_audio)],\n",
    "    'LOW_MOO': [get_data.GetDataSimple(HPB_MBY_DATA,HPB_MBY_LABEL_LOW_MOO, fs, useful.file_to_audio)],\n",
    "    'PULSE': [get_data.GetDataSimple(HPB_MBY_DATA,HPB_MBY_LABEL_PULSE, fs, useful.file_to_audio)],\n",
    "    'SWOOP': [get_data.GetDataSimple(HPB_MBY_DATA,HPB_MBY_LABEL_SWOOP, fs, useful.file_to_audio)],\n",
    "    'NOISE': [get_data.GetDataSimple(HPB_MBY_DATA,HPB_MBY_NOISE, fs, useful.file_to_audio)]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__collected samples__\n",
      "MOO :  23\n",
      "HIGH_MOO :  15\n",
      "LOW_MOO :  28\n",
      "PULSE :  24\n",
      "SWOOP :  44\n",
      "NOISE :  24\n"
     ]
    }
   ],
   "source": [
    "samples, labels = useful.get_samples(get_data_dict, labels_set, label_to_num)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/.conda/envs/ubm/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# from scipy.interpolate import interp1d\n",
    "#\n",
    "all_features = []\n",
    "nfft = 128 # 256 # 256 # 256 #128 # 256 #128\n",
    "to_remove = []\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    sample = samples[i]\n",
    "    feat_b = get_feature(sample, nfft)\n",
    "    all_features.append(feat_b) #152 129"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "54"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min([len(feat) for feat in all_features])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "normalized_features, mean_std = normalize_features(all_features, False)\n",
    "averaged_features = [average_features(feat, 3, feat.shape[1]) for feat in all_features]\n",
    "averaged_normalised_features = [average_features(feat, 3, feat.shape[1]) for feat in normalized_features]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import final.cross_validation as cv\n",
    "from final.cross_validation import *\n",
    "import importlib\n",
    "importlib.reload(cv)\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "n_folds = 2\n",
    "# cv_output = cv.split_data_for_cross_validation(samples, labels, n_folds, test_ratio=0.2)\n",
    "cv_output = cv.split_data_for_cross_validation(normalized_features, labels, n_folds, test_ratio=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Pickle for reading in Python\n",
    "output = open('cv_output_hpb_mfcc_norm' + \".pkl\", \"wb\")\n",
    "pickle.dump({'cv_output': cv_output, 'label_map': label_to_num, 'num_map': num_to_label}, output)\n",
    "output.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
